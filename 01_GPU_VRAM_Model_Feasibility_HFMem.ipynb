{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BluTeITay_3Q"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/urcraft/llm_lecture_notebooks/blob/main/01_GPU_VRAM_Model_Feasibility_HFMem.ipynb\">   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QorMnxqEy_3U"
      },
      "source": [
        "## Install Dependencies\n",
        "---\n",
        "\n",
        "We install `uv` and verify that `uvx` is available in this runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MZxXjNyTy_3V",
        "outputId": "6315ca9c-6ea7-42ed-eb7c-5da80c28c77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "downloading uv 0.10.4 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "uv 0.10.4\n",
            "uvx 0.10.4\n"
          ]
        }
      ],
      "source": [
        "!apt -qq update\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!/usr/local/bin/uv --version\n",
        "!/usr/local/bin/uvx --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0P2a4zy_3W"
      },
      "source": [
        "## Run hf-mem on Popular Hugging Face LLMs\n",
        "---\n",
        "\n",
        "Each command runs separately (no loop).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_HgNOGo7y_3X",
        "outputId": "5cb5a3d6-d4ec-475a-c9a0-68f0b4fc9538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\u001b[2mInstalled \u001b[1m11 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n",
            "\u001b[38;2;244;183;63m┌┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┐\u001b[0m\n",
            "\u001b[38;2;244;183;63m├┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│            INFERENCE MEMORY ESTIMATE FOR            │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│      https://hf.co/MiniMaxAI/MiniMax-M2 @ main      │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┬────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ TOTAL MEMORY   │ 214.32 GB (228.70B PARAMS)         │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ REQUIREMENTS   │ ██████████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ F32            │ 0.23 / 214.32 GB                   │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 62.65M PARAMS  │ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ F8_E4M3        │ 211.79 / 214.32 GB                 │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 227.41B PARAMS │ ██████████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ BF16           │ 2.29 / 214.32 GB                   │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 1.23B PARAMS   │ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m└────────────────┴────────────────────────────────────┘\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/bin/uvx hf-mem --model-id MiniMaxAI/MiniMax-M2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DOMlZV6_y_3X",
        "outputId": "b2d3b042-4597-4223-eceb-1fb86869a6f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-mem==0.4.4                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2manyio==4.12.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcertifi==2026.1.4                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpcore==1.0.9                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.11                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mh2==4.3.0                                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mh11==0.16.0                                                                   \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhyperframe==6.1.0                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhpack==4.1.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[38;2;244;183;63m┌┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┐\u001b[0m\n",
            "\u001b[38;2;244;183;63m├┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│            INFERENCE MEMORY ESTIMATE FOR             │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│          https://hf.co/zai-org/GLM-5 @ main          │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┬─────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ TOTAL MEMORY   │ 1404.18 GB (753.86B PARAMS)         │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ REQUIREMENTS   │ ███████████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼─────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ BF16           │ 1404.18 / 1404.18 GB                │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 753.86B PARAMS │ ███████████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼─────────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ F32            │ 0.00 / 1404.18 GB                   │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 19.46K PARAMS  │ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m└────────────────┴─────────────────────────────────────┘\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/bin/uvx hf-mem --model-id zai-org/GLM-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y1alIMjEy_3X",
        "outputId": "87591945-f242-4ed0-d7a2-4a03fbbed3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-mem==0.4.4                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2manyio==4.12.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcertifi==2026.1.4                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpcore==1.0.9                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.11                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mh2==4.3.0                                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mh11==0.16.0                                                                   \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhyperframe==6.1.0                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhpack==4.1.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[38;2;244;183;63m┌┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┬┐\u001b[0m\n",
            "\u001b[38;2;244;183;63m├┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│          INFERENCE MEMORY ESTIMATE FOR          │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│       https://hf.co/Qwen/Qwen3-4B @ main        │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┬────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ TOTAL MEMORY   │ 7.49 GB (4.02B PARAMS)         │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ REQUIREMENTS   │ ██████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m├────────────────┼────────────────────────────────┤\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ BF16           │ 7.49 / 7.49 GB                 │\u001b[0m\n",
            "\u001b[38;2;244;183;63m│ 4.02B PARAMS   │ ██████████████████████████████ │\u001b[0m\n",
            "\u001b[38;2;244;183;63m└────────────────┴────────────────────────────────┘\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/bin/uvx hf-mem --model-id Qwen/Qwen3-4B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Xoa_Y76y_3Y",
        "outputId": "fda2e774-ff41-4571-8249-e468224e7c40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7WJrcSy_3Y"
      },
      "source": [
        "## Notes\n",
        "---\n",
        "\n",
        "- If a model is gated/private, authenticate in Colab first (e.g., `huggingface-cli login`).\n",
        "- `hf-mem` is experimental and may change across releases.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HF_MEM_Colab_UVX.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}